{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Correlation .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraBabakN/Model-Search/blob/master/Correlation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tZkNNNAR0OX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10('./dataset', train=True, download=True,\n",
        "                                         transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "\n",
        "def get_num_correct(preds, labels):\n",
        "    return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnbzkY4OSERd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.01\n",
        "batch_size = 200\n",
        "dataset_size = 50000\n",
        "epoch_num = 40\n",
        "cor_ths = 0.65\n",
        "data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fMZtdCLRDgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myModel(nn.Module):\n",
        "    def __init__(self, block,groups=1, width_per_group=64):\n",
        "        super(myModel, self).__init__()\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3,64, kernel_size=7, stride=2, padding=3,bias=False)\n",
        "        self.bn1 = norm_layer(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64)\n",
        "        self.layer2 = self._make_layer(block, 64)\n",
        "        self.layer3 = self._make_layer(block, 128, stride=2)\n",
        "        self.layer4 = self._make_layer(block, 128,)\n",
        "        self.layer5 = self._make_layer(block, 256, stride=2)\n",
        "        self.layer6 = self._make_layer(block, 256)\n",
        "        self.layer7 = self._make_layer(block, 512, stride=2)\n",
        "        self.layer8 = self._make_layer(block, 512)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 , 10)\n",
        "\n",
        "    def _make_layer(self, block, planes, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes, stride),\n",
        "                norm_layer(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.layer7(x)\n",
        "        x = self.layer8(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "class BasicBlock(nn.Module): \n",
        "    expansion = 1 \n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        norm_layer = nn.BatchNorm2d\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out    \n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "def myResnet(pretrained=False, progress=True, **kwargs):\n",
        "    return myModel(BasicBlock,**kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mktu3m_1wxqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myNet = myResnet()\n",
        "optimizer = optim.Adam(myNet.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVp38ZWVHkE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6129df9e-7262-40b3-d3af-1b84b5a979f1"
      },
      "source": [
        "correct = 0 \n",
        "for batch in data_loader:\n",
        "    images, labels = batch\n",
        "    images = images.cuda() \n",
        "    labels = labels.cuda()\n",
        "    preds = myNet(images)\n",
        "    correct = correct + get_num_correct(preds,labels)\n",
        "print(\"accuracy\" , correct/dataset_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GxYU4vBDNzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [] \n",
        "layers.append(myNet.conv1.weight)\n",
        "layers.append(list(myNet.layer1.modules())[2].weight)\n",
        "layers.append(list(myNet.layer1.modules())[5].weight)\n",
        "layers.append(list(myNet.layer2.modules())[2].weight)\n",
        "layers.append(list(myNet.layer2.modules())[5].weight)\n",
        "layers.append(list(myNet.layer3.modules())[2].weight)\n",
        "layers.append(list(myNet.layer3.modules())[5].weight)\n",
        "layers.append(list(myNet.layer4.modules())[2].weight)\n",
        "layers.append(list(myNet.layer4.modules())[5].weight)\n",
        "layers.append(list(myNet.layer5.modules())[2].weight)\n",
        "layers.append(list(myNet.layer5.modules())[5].weight)\n",
        "layers.append(list(myNet.layer6.modules())[2].weight)\n",
        "layers.append(list(myNet.layer6.modules())[5].weight)\n",
        "layers.append(list(myNet.layer7.modules())[2].weight)\n",
        "layers.append(list(myNet.layer7.modules())[5].weight)\n",
        "layers.append(list(myNet.layer8.modules())[2].weight)\n",
        "layers.append(list(myNet.layer8.modules())[5].weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcM1VLIe5d6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = 0 \n",
        "for num in range (len(layers)): \n",
        "  output= [] \n",
        "  convLayer = layers[num]\n",
        "  layer = convLayer.clone().detach().cpu()\n",
        "  num_filter = layer.shape[0] \n",
        "  layer = layer.reshape( num_filter , -1 )\n",
        "  for i in range( num_filter - 2 ):\n",
        "      for j in range ( i + 1  , num_filter):\n",
        "        corr = np.corrcoef(layer[i],layer[j])\n",
        "        if ( abs(corr[0,1]) > cor_ths ):\n",
        "          output.append([i,j])\n",
        "  print(len(output)/num_filter/(num_filter-1) * 200)\n",
        "  for couple in output:\n",
        "    (layers[num])[couple[1]] = 0 \n",
        "    counter = counter + 1 \n",
        "print(counter)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHz8HbzmNjMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7b3c23a-48c7-48ae-c80e-35b16e22ebaf"
      },
      "source": [
        "correct = 0 \n",
        "for batch in data_loader:\n",
        "    images, labels = batch\n",
        "    images = images.cuda() \n",
        "    labels = labels.cuda()\n",
        "    preds = myNet(images)\n",
        "    correct = correct + get_num_correct(preds,labels)\n",
        "print(\"accuracy\" , correct/dataset_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.95176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akl0FyMl7ce4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "importance_matrices = [] \n",
        "for layer in layers: \n",
        "  x = torch.norm(layer , dim=(1,2,3) , p = 1 ) \n",
        "  x = x / sum(x)\n",
        "  importance_matrices.append(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVvWgLPUdpGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0 \n",
        "counter = 0 \n",
        "for mat in importance_matrices: \n",
        "  plt.figure(i)\n",
        "  t= range(mat.shape[0])\n",
        "  plt.plot(t , mat[t].clone().detach().cpu() , \"*\")\n",
        "  \n",
        "  plt.show \n",
        "  i = i + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOhuTeskTnau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = next(iter(data_loader))\n",
        "images, labels = batch\n",
        "images = images.cuda() \n",
        "labels = labels.cuda()\n",
        "x = myNet.conv1(images)\n",
        "x = myNet.bn1(x)\n",
        "x = myNet.relu(x)\n",
        "x = myNet.maxpool(x)\n",
        "x = myNet.layer1(x)\n",
        "x = myNet.layer2(x)\n",
        "l3 = myNet.layer3(x)\n",
        "l4 = myNet.layer4(l3)\n",
        "l5 = myNet.layer5(l4)\n",
        "l6= myNet.layer6(l5)\n",
        "l7 = myNet.layer7(l6) \n",
        "l8 = myNet.layer8(l7) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpULVFA5P0wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modulList = list(myNet.layer3.modules())\n",
        "# step 1\n",
        "x1 = modulList[2](x)\n",
        "x1 = modulList[3](x1)\n",
        "x1 = modulList[4](x1)\n",
        "x1 = modulList[5](x1)\n",
        "x1 = modulList[6](x1)\n",
        "#step 2 \n",
        "x2 = modulList[7](x) \n",
        "\n",
        "modulList = list(myNet.layer5.modules())\n",
        "# Step 1\n",
        "x5 = modulList[2](l4)\n",
        "x5 = modulList[3](x5)\n",
        "x5 = modulList[4](x5)\n",
        "x5 = modulList[5](x5)\n",
        "x5 = modulList[6](x5)\n",
        "# Step 2\n",
        "x6 = modulList[7](l4)\n",
        "\n",
        "modulList = list(myNet.layer7.modules())\n",
        "#Step 1 \n",
        "x9 = modulList[2](l6)\n",
        "x9 = modulList[3](x9)\n",
        "x9 = modulList[4](x9)\n",
        "x9 = modulList[5](x9)\n",
        "x9 = modulList[6](x9)\n",
        "#Step 2\n",
        "x10 = modulList[7](l6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_JRTO1bXnr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "659baab1-ab84-4f8d-ffb1-2e51d5828e36"
      },
      "source": [
        "x1_0 = x1[0].clone().detach().cpu()\n",
        "x2_0 = x2[0].clone().detach().cpu() \n",
        "x1_0[1].shape \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEBsX5448TWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cbe18268-bc28-4476-c6a9-66e932b073b3"
      },
      "source": [
        "output= []\n",
        "x1_0 = x1.clone().detach().cpu()\n",
        "x2_0 = x2.clone().detach().cpu() \n",
        "x5_0 = x5.clone().detach().cpu()\n",
        "x6_0 = x6.clone().detach().cpu()\n",
        "x9_0 = x9.clone().detach().cpu()\n",
        "x10_0 = x10.clone().detach().cpu()\n",
        "\n",
        "for filter in range(2):\n",
        "  corr = np.corrcoef(x1_0[filter].reshape(-1) , x2_0[filter].reshape(-1))\n",
        "  print(corr.shape)\n",
        "  if ( corr[0,1] > cor_ths ):\n",
        "    print(\"1\" , filter)\n",
        "  corr = np.corrcoef(x5_0[filter].reshape(-1) , x6_0[filter].reshape(-1))\n",
        "  if ( corr[0,1] > cor_ths ):\n",
        "    print(\"2\" , filter)\n",
        "  corr = np.corrcoef(x9_0[filter].reshape(-1) , x10_0[filter].reshape(-1))\n",
        "  if ( corr[0,1] > cor_ths ):\n",
        "    print(\"3\" , filter)\n",
        "\n",
        "\n",
        "# for filter in range(x5_0.shape[0]):\n",
        "#   corr = np.corrcoef(x5_0[filter].reshape(-1) , x6_0[filter].reshape(-1))\n",
        "#   if ( corr[0,1] > cor_ths ):\n",
        "#     output.append(filter)\n",
        "# print(len(output)/x5_0.shape[0] * 100)   \n",
        "\n",
        "\n",
        "\n",
        "# output= []\n",
        "# for filter in range(x9_0.shape[0]):\n",
        "#   corr = np.corrcoef(x9_0[filter].reshape(-1) , x10_0[filter].reshape(-1))\n",
        "#   if ( corr[0,1] > cor_ths ):\n",
        "#     output.append(filter)\n",
        "# print(len(output)/x10_0.shape[0] * 100)   \n",
        "\n",
        "\n",
        "\n",
        "# x11 = nn.ReLU(inplace=True)(x9)\n",
        "# x12 = nn.ReLU(inplace=True)(x10)\n",
        "# x9_0 = x9[0].clone().detach().cpu()\n",
        "# x10_0 = x12[0].clone().detach().cpu()\n",
        "# output= []\n",
        "# for filter in range(x9_0.shape[0]):\n",
        "#   corr = np.corrcoef(x9_0[filter].reshape(-1) , x10_0[filter].reshape(-1))\n",
        "#   if ( corr[0,1] > cor_ths ):\n",
        "#     output.append(filter)\n",
        "# print(len(output)/x10_0.shape[0] * 100)   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2)\n",
            "(2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonRydU3Bvml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output= []\n",
        "for i in range (200):\n",
        "  y9 = x9[i].clone().detach().cpu()\n",
        "  y10 = x10[i].clone().detach().cpu()\n",
        "  corr = np.corrcoef(abs(y9.reshape(-1)) , abs(y10.reshape(-1)))\n",
        "  if ( corr[0,1] > cor_ths ):\n",
        "    output.append([i])\n",
        "  print(corr[0,1])\n",
        "# print(len(output)/x10_0.shape[0] * 100)   \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}